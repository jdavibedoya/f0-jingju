{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Singing pitch estimation in jingju music.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdavibedoya/f0-jingju/blob/master/Singing_pitch_estimation_in_jingju_music.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzGUN1j1CldW",
        "colab_type": "text"
      },
      "source": [
        "#Singing pitch estimation in jingju music\n",
        "This notebook is designed to:\n",
        "1. Extract singing pitch estimations in jingju music using three different algorithms (CREPE, pYin and MELODIA)\n",
        "2. Evaluate the accuracy of these pitch estimations.\n",
        "3. Compare the performance of the algorithms used.\n",
        "\n",
        "Singing pitch estimation may refer to either monophonic melody (one singer) or predominant melody from polyphonic music signals (a singer with musical accompaniment). \n",
        "- For monophonic melody extraction, here are used the recordings from the <a href = \" https://zenodo.org/record/832736 \">Jingju a cappella singing pitch contour segmentation ground truth dataset</a> (hereafter the a cappella recordings). \n",
        "- For predominant melody extraction, here are used the recordings used in <a href = \" https://repositori.upf.edu/handle/10230/34975 \">Comparision of the singing style of two jingju schools</a> (hereafter the commercial recordings).\n",
        "\n",
        "Note: Each cell begins with a comment that explains what is done in that cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7RHykUErhNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# installing the required packages\n",
        "%pip install --upgrade tensorflow  # if you don't already have tensorflow >= 2.0.0\n",
        "%pip install crepe\n",
        "%pip install essentia"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMk3DL6Zrama",
        "colab_type": "code",
        "outputId": "3076a9cd-8a48-4a87-c4e4-3c579e42634f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# imports\n",
        "import os\n",
        "import shutil\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mir_eval\n",
        "import crepe\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from essentia.standard import PitchYinProbabilistic, MonoLoader, PitchMelodia, EqualLoudness\n",
        "#from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "main_dir = \"drive/Shared drives/MIR Project/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbHXiFVjWN65",
        "colab_type": "text"
      },
      "source": [
        "## A cappella\n",
        "\n",
        "It would be desirable that the recordings had the metadata and annotations in terms of the jingju musical system. As a further matter, this would be useful for studying jingju singing pitch estimation in terms of its musical system elements (not addressed here).\n",
        "\n",
        "The a cappella recordings do not have these metadata and annotations, but the <a href = \" https://zenodo.org/record/3251761 \">Jingju a Cappella Recordings Collection</a> (JaCRC), which include these recordings and many more (albeit with a different name), does.\n",
        "\n",
        "The following cell defines and executes a function that matches the <a href = \" https://zenodo.org/record/ \">a cappella recordings</a> with the appropriate <a href = \" https://zenodo.org/record/3251761 \">JaCRC</a> recordings using a simple similarity function (cosine of the angle between audio vectors). The results of this matching are stored in the `file_matching.csv` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6cnuaHzHuAF",
        "colab_type": "code",
        "outputId": "371523c2-e996-47e5-9f70-12cfa7eadd25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# function that matches the a cappella recordings with the appropriate JaCRC recordings using a cosine similarity function\n",
        "unlabeled_audio = main_dir + \"raw data/Audio_melody\"               \n",
        "\n",
        "def match_audio(x, unlabeled):\n",
        "    '''\n",
        "    x: unlabeled audio\n",
        "    unlabeled: unlabeled audio location\n",
        "    '''\n",
        "    labeled_audio = main_dir + \"raw data/JaCRC\"\n",
        "    better_match = [unlabeled, None, 0] # [unlabeled, labeled, similarity]\n",
        "    max_similarity = 0\n",
        "    fs = 44100\n",
        "    for root, dirs, files in os.walk(labeled_audio):\n",
        "        if root == labeled_audio: # exclude Accompaniment and Mixing folders\n",
        "            for file in files:\n",
        "                if file.endswith('.wav') or file.endswith('.WAV'): # WAV files\n",
        "                    file_name = os.path.join(root,file)\n",
        "                    y = MonoLoader(filename = file_name, downmix = 'mix', sampleRate = fs)() # load labeled audio \n",
        "                    if (np.abs(len(x)-len(y)) < 10): # only compare audios with a length difference of a maximum of 10 samples\n",
        "                        minor_length = min(len(x), len(y))\n",
        "                        x = x[:minor_length]\n",
        "                        y = y[:minor_length]                          \n",
        "                        similarity = np.dot(x, y) / ( np.linalg.norm(x)*np.linalg.norm(y) ) # cosine of the angle between audio vectors\n",
        "                        if similarity  > max_similarity:\n",
        "                            max_similarity = similarity \n",
        "                            better_match[1] = file_name\n",
        "                            better_match[2] = similarity \n",
        "    return better_match\n",
        "\n",
        "# executing the match_audio function in the a cappella recordings\n",
        "matches = 0\n",
        "with open(main_dir + 'file_matching.csv', mode='r') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
        "  \n",
        "    for root, dirs, files in os.walk(unlabeled_audio):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav'): # WAV files\n",
        "                file_name = os.path.join(root,file)\n",
        "                x = MonoLoader(filename = file_name)()\n",
        "                #match = match_audio(x, file_name)\n",
        "                print(file, match)\n",
        "                if match[2] != 0:\n",
        "                    matches += 1\n",
        "                    csv_writer.writerow(match)\n",
        "\n",
        "print('{} Matches'.format(matches))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44 Matches\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu14GtLslw_C",
        "colab_type": "text"
      },
      "source": [
        "The following two cells copy the pitch track annotations and their respective a cappella recordings from the `raw data` folder, which contains the original datasets, and then rename them using the the `file_matching.csv file`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOZDYuScXy3t",
        "colab_type": "code",
        "outputId": "0ca1891f-8c58-4964-a585-675ee27648fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# copying the pitch track annotations and renaming them using the file_matching.csv file\n",
        "test_csv = main_dir + \"a cappella/f0_ground_truth/\"\n",
        "#os.mkdir(test_csv)\n",
        "count_copied_and_renamed = 0\n",
        "\n",
        "# copying csv files\n",
        "ground_truth_folder = main_dir + \"raw data/SMC2016-master/dataset/groundtruth\"\n",
        "for root, dirs, files in os.walk(ground_truth_folder):\n",
        "     for file in files:\n",
        "          if file.endswith('pitchtrack.csv'): # WAV files\n",
        "              file_name = os.path.join(root,file)\n",
        "              shutil.copy(file_name, test_csv)\n",
        "\n",
        "# renaming csv files\n",
        "with open(main_dir + 'file_matching.csv', mode='r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    for row in csv_reader:\n",
        "        source_name = row[0].split(\"/\")[-2] + \"_\" + row[0].split(\"/\")[-1].split(\".\")[-2] + \"_pitchtrack.csv\"\n",
        "        source = test_csv + source_name\n",
        "        if os.path.isfile(source): # check if file exists\n",
        "            count_copied_and_renamed += 1\n",
        "            target = test_csv + row[1].split(\"/\")[-1].split(\".\")[-2] + \".csv\"\n",
        "            os.rename(source, target)\n",
        "\n",
        "print('{} csv files copied and renamed'.format(count_copied_and_renamed))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41 csv files copied and renamed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeFz7VOUNuY9",
        "colab_type": "code",
        "outputId": "0fd90215-b710-4365-a7e1-88dc19e8fe33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# copying the a cappella recordings and renaming them using the file_matching.csv file\n",
        "test_audio = main_dir + \"a cappella/audio/\"\n",
        "test_csv = main_dir + \"a cappella/f0_ground_truth/\"\n",
        "#os.mkdir(test_audio)\n",
        "count_copied_and_renamed = 0\n",
        "\n",
        "with open(main_dir + 'file_matching.csv', mode='r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    for row in csv_reader:\n",
        "        if row[1] != \"\":\n",
        "          pitch_track = row[1].split(\"/\")[-1].split(\".\")[-2] + \".csv\"\n",
        "          source = test_csv + pitch_track\n",
        "          if os.path.isfile(source): # check if pitch track exists\n",
        "              count_copied_and_renamed += 1\n",
        "              copy = shutil.copy(row[0], test_audio)\n",
        "              target = test_audio + row[1].split(\"/\")[-1].split(\".\")[-2] + \".wav\"\n",
        "              os.rename(copy, target)\n",
        "\n",
        "print('{} wav files copied and renamed'.format(count_copied_and_renamed))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41 wav files copied and renamed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNRT7Xp_tRuF",
        "colab_type": "text"
      },
      "source": [
        "### pYIN\n",
        "\n",
        "The <a href = \" https://essentia.upf.edu/reference/std_PitchYinProbabilistic.html \">pYIN</a> algorithm computes the pitch track of a mono audio signal.\n",
        "\n",
        "The following cell runs pYin in the a cappella recordings for three frame sizes `[512, 1024, 2048]` and three hop sizes `[256, 441, 512]`. Then it stores the prediction with the best `Raw Pitch Accuracy` performance for each audio in the `a cappella/pYin/` folder.\n",
        "\n",
        "Here, the best `Raw Pitch Accuracy` performance for each audio is determined with the `melody.evaluate` method of the `mir_eval` library. A tolerance of 50 cents is used.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5kjzomCranM",
        "colab_type": "code",
        "outputId": "cf3fed41-6f6f-4a40-e434-e280d19f6d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# executing and storing pYin - a cappella\n",
        "test_csv = main_dir + \"a cappella/f0_ground_truth/\"\n",
        "test_audio = main_dir + \"a cappella/audio/\"\n",
        "pYin_csv = main_dir + \"a cappella/pYin/\"\n",
        "#os.mkdir(pYin_csv)\n",
        "\n",
        "frameSizes = [512, 1024, 2048]\n",
        "hopSizes = [256, 441, 512]\n",
        "fs = 44100\n",
        "count_predictions = 0\n",
        "\n",
        "for root, dirs, files in os.walk(test_csv):\n",
        "    for file in files:\n",
        "        file_name = os.path.join(root,file)\n",
        "        # reading ground-truth\n",
        "        gt_time = []\n",
        "        gt_pitch = []\n",
        "        with open(file_name, mode='r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            for row in csv_reader:\n",
        "                gt_time.append(float(row[1]))\n",
        "                gt_pitch.append(float(row[2]))\n",
        "\n",
        "        best_score = 0\n",
        "        x = MonoLoader(filename = test_audio + file.split(\".\")[-2] + \".wav\", downmix = 'mix', sampleRate = fs)() # load labeled audio\n",
        "        for frameSize in frameSizes:\n",
        "            for hopSize in hopSizes:\n",
        "                # executing pYin\n",
        "                pYIN = PitchYinProbabilistic(frameSize = frameSize, hopSize = hopSize, preciseTime = True, outputUnvoiced = 'negative')\n",
        "                pyin_pitch , pyin_probabilities = pYIN(x)\n",
        "                pyin_time = np.arange(0,len(pyin_pitch))*hopSize/fs\n",
        "\n",
        "                # pyin_pitch[np.argwhere(pyin_probabilities < 0.75)] = 0 # discard prediction with confidence < 0.75\n",
        "                scores = mir_eval.melody.evaluate(gt_time, gt_pitch, pyin_time, pyin_pitch, cent_tolerance=50)\n",
        "                if scores['Raw Pitch Accuracy'] > best_score:\n",
        "                    best_score = scores['Raw Pitch Accuracy']\n",
        "                    best_frameSize = frameSize\n",
        "                    best_hopSize = hopSize\n",
        "                    best_pyin_time = pyin_time\n",
        "                    best_pyin_pitch = pyin_pitch\n",
        "                    best_pyin_probabilities = pyin_probabilities\n",
        "        \n",
        "        # storing pYIN prediction\n",
        "        with open(pYin_csv + file.split(\".\")[-2] + '.' + str(best_frameSize) + '.' + str(best_hopSize) + \".csv\", 'w') as csv_file:\n",
        "            count_predictions +=1\n",
        "            csv_writer = csv.writer(csv_file, delimiter=',')\n",
        "            for i in range(len(best_pyin_pitch)):\n",
        "                csv_writer.writerow([best_pyin_time[i], best_pyin_pitch[i], best_pyin_probabilities[i]])\n",
        "\n",
        "print('{} pYIN predictions stored'.format(count_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41 pYIN predictions stored\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEqDfD5e398M",
        "colab_type": "text"
      },
      "source": [
        "Next cell computes the pYin performance on the a cappella recordings using the predictions stored in the previous cell. The metric used is the `Raw Pitch Accuracy` which is computed using the `mir_eval.melody.evaluate` method with tolerances of 10, 25 and 50 cents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IMlYxxI0D4p",
        "colab_type": "code",
        "outputId": "8bb15c4a-7e16-4213-823e-6fc75d3b0324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# evaluating pYin - a cappella\n",
        "test_csv = main_dir + \"a cappella/f0_ground_truth/\"\n",
        "pYin_csv = main_dir + \"a cappella/pYin/\"\n",
        "\n",
        "cent_tolerances = [10, 25, 50]\n",
        "pYin_RPA = {10:[[],[]], 25:[[],[]], 50:[[],[]]} # raw pitch accuracy\n",
        "\n",
        "for root, dirs, files in os.walk(pYin_csv):\n",
        "    for file in files:\n",
        "        file_name = os.path.join(root,file)\n",
        "        # reading pYin prediction\n",
        "        pYin_time = []\n",
        "        pYin_pitch = []\n",
        "        pYin_probabilities = []\n",
        "        with open(file_name, mode='r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            for row in csv_reader:\n",
        "                pYin_time.append(float(row[0]))\n",
        "                pYin_pitch.append(float(row[1]))\n",
        "                pYin_probabilities.append(float(row[2]))\n",
        "\n",
        "        pYin_time = np.array(pYin_time)\n",
        "        pYin_pitch = np.array(pYin_pitch)\n",
        "        pYin_probabilities = np.array(pYin_probabilities)\n",
        "\n",
        "        # reading ground-truth\n",
        "        gt_time = []\n",
        "        gt_pitch = []\n",
        "        with open(test_csv + file.split('.')[-4] + '.csv', mode='r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            for row in csv_reader:\n",
        "                gt_time.append(float(row[1]))\n",
        "                gt_pitch.append(float(row[2]))\n",
        "  \n",
        "        # pyin_pitch[np.argwhere(pyin_probabilities < 0.75)] = 0 # discard prediction with confidence < 0.75    \n",
        "        for cent_tolerance in cent_tolerances:\n",
        "            scores = mir_eval.melody.evaluate(gt_time, gt_pitch, pYin_time, pYin_pitch, cent_tolerance=cent_tolerance)\n",
        "            pYin_RPA[cent_tolerance][0].append( scores['Raw Pitch Accuracy'] )\n",
        "            pYin_RPA[cent_tolerance][1].append( len(gt_time) )\n",
        "\n",
        "print('pYin - a cappella audio')\n",
        "for cent_tolerance in cent_tolerances:\n",
        "    RPA_mean = np.average( pYin_RPA[cent_tolerance][0], weights = pYin_RPA[cent_tolerance][1] )\n",
        "    RPA_std = np.sqrt( np.average((pYin_RPA[cent_tolerance][0] - RPA_mean)**2, weights = pYin_RPA[cent_tolerance][1]) )\n",
        "    print(str(cent_tolerance) + ' cents \\tRaw Pitch Accuracy: ', \"{0:.3f}\".format(RPA_mean), ' ± ', \"{0:.3f}\".format(RPA_std))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pYin - a cappella audio\n",
            "10 cents \tRaw Pitch Accuracy:  0.705  ±  0.088\n",
            "25 cents \tRaw Pitch Accuracy:  0.912  ±  0.050\n",
            "50 cents \tRaw Pitch Accuracy:  0.971  ±  0.017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU-gCT_-o6Nb",
        "colab_type": "text"
      },
      "source": [
        "### CREPE\n",
        "\n",
        "<a href = \" https://github.com/marl/crepe \">CREPE </a> is a monophonic pitch tracker based on a deep convolutional neural network operating directly on the time-domain waveform input.\n",
        "\n",
        "The following cell runs CREPE in the a cappella recordings for two time steps `[5, 10]`, and then stores the prediction with the best `Raw Pitch Accuracy` performance for each audio in the `a cappella/crepe/` folder.\n",
        "\n",
        "Here, the best `Raw Pitch Accuracy` performance for each audio is determined with the `melody.evaluate` method of the `mir_eval` library. A tolerance of 50 cents is used.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKLhdZTc2t8i",
        "colab_type": "code",
        "outputId": "581d3936-bec9-4077-a375-d2d9c152edc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# executing and storing crepe - a cappella\n",
        "test_csv = main_dir + \"a cappella/f0_ground_truth/\"\n",
        "test_audio = main_dir + \"a cappella/audio/\"\n",
        "crepe_csv = main_dir + \"a cappella/crepe/\"\n",
        "os.mkdir(crepe_csv)\n",
        "\n",
        "fs = 44100\n",
        "steps = [5, 10, 15]\n",
        "count_predictions = 0\n",
        "\n",
        "for root, dirs, files in os.walk(test_csv):\n",
        "    for file in files:\n",
        "        file_name = os.path.join(root,file)\n",
        "        # reading ground-truth\n",
        "        gt_time = []\n",
        "        gt_pitch = []\n",
        "        with open(file_name, mode='r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            for row in csv_reader:\n",
        "                gt_time.append(float(row[1]))\n",
        "                gt_pitch.append(float(row[2]))\n",
        "\n",
        "        best_score = 0\n",
        "        audio = MonoLoader(filename = test_audio + file.split(\".\")[-2] + \".wav\", downmix = 'mix', sampleRate = fs)() # load labeled audio \n",
        "        for step in steps:\n",
        "            # executing crepe\n",
        "            crp_time, crp_frequency, crp_confidence, activation = crepe.predict(audio, fs, step_size= step, viterbi=True, verbose=0)\n",
        "\n",
        "            #crp_freq[np.argwhere(crp_confidence < 0.75)] = 0 # discard prediction with confidence < 0.75\n",
        "            scores = mir_eval.melody.evaluate(gt_time, gt_pitch, crp_time, crp_frequency, cent_tolerance=50)\n",
        "            if scores['Raw Pitch Accuracy'] > best_score:\n",
        "                best_score = scores['Raw Pitch Accuracy']\n",
        "                best_step = step\n",
        "                best_crp_time = crp_time\n",
        "                best_crp_frequency = crp_frequency\n",
        "                best_crp_confidence = crp_confidence\n",
        "\n",
        "        # storing crepe output\n",
        "        with open(crepe_csv + file.split(\".\")[-2] + '.' + str(best_step) + \".csv\", mode='w') as csv_file:\n",
        "            count_predictions +=1\n",
        "            csv_writer = csv.writer(csv_file, delimiter=',')\n",
        "            for i in range(len(best_crp_time)):\n",
        "                csv_writer.writerow([best_crp_time[i], best_crp_frequency[i], best_crp_confidence[i]])\n",
        "\n",
        "print('{} CREPE predictions stored'.format(count_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41 CREPE predictions stored\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4YfmHrDvrhj",
        "colab_type": "text"
      },
      "source": [
        "Next cell computes the CREPE performance on the a cappella recordings using the predictions stored in the previous cell. The metric used is the `Raw Pitch Accuracy` which is computed using the `mir_eval.melody.evaluate` method with tolerances of 10, 25 and 50 cents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt91JukTwc5h",
        "colab_type": "code",
        "outputId": "763e174c-1943-4a30-fadf-4515736eeee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# evaluating crepe - a cappella\n",
        "test_csv = main_dir + \"a cappella/f0_ground_truth/\"\n",
        "crepe_csv = main_dir + \"a cappella/crepe/\"\n",
        "\n",
        "cent_tolerances = [10, 25, 50]\n",
        "crp_RPA = {10:[[],[]], 25:[[],[]], 50:[[],[]]} # raw pitch accuracy\n",
        "\n",
        "for root, dirs, files in os.walk(crepe_csv):\n",
        "    for file in files:\n",
        "        file_name = os.path.join(root,file)\n",
        "        # reading crepe prediction\n",
        "        crp_time = []\n",
        "        crp_freq = []\n",
        "        crp_confidence = []\n",
        "        with open(file_name, mode='r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            for row in csv_reader:\n",
        "                crp_time.append(float(row[0]))\n",
        "                crp_freq.append(float(row[1]))\n",
        "                crp_confidence.append(float(row[2]))\n",
        "\n",
        "        crp_time = np.array(crp_time)\n",
        "        crp_freq = np.array(crp_freq)\n",
        "        crp_confidence = np.array(crp_confidence)\n",
        "\n",
        "        # reading ground-truth\n",
        "        gt_time = []\n",
        "        gt_pitch = []\n",
        "        with open(test_csv + file.split('.')[-3] + '.csv', mode='r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            for row in csv_reader:\n",
        "                gt_time.append(float(row[1]))\n",
        "                gt_pitch.append(float(row[2]))\n",
        "  \n",
        "        #crp_freq[np.argwhere(crp_confidence < 0.75)] = 0 # discard prediction with confidence < 0.75    \n",
        "        for cent_tolerance in cent_tolerances:\n",
        "            scores = mir_eval.melody.evaluate(gt_time, gt_pitch, crp_time, crp_freq, cent_tolerance=cent_tolerance)\n",
        "            crp_RPA[cent_tolerance][0].append( scores['Raw Pitch Accuracy'] )\n",
        "            crp_RPA[cent_tolerance][1].append( len(gt_time) )\n",
        "\n",
        "print('crepe - a cappella audio')\n",
        "for cent_tolerance in cent_tolerances:\n",
        "    RPA_mean = np.average( crp_RPA[cent_tolerance][0], weights = crp_RPA[cent_tolerance][1] )\n",
        "    RPA_std = np.sqrt( np.average((crp_RPA[cent_tolerance][0] - RPA_mean)**2, weights = crp_RPA[cent_tolerance][1]) )\n",
        "    print(str(cent_tolerance) + ' cents \\tRaw Pitch Accuracy: ', \"{0:.3f}\".format(RPA_mean), ' ± ', \"{0:.3f}\".format(RPA_std))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "crepe - a cappella audio\n",
            "10 cents \tRaw Pitch Accuracy:  0.804  ±  0.060\n",
            "25 cents \tRaw Pitch Accuracy:  0.942  ±  0.023\n",
            "50 cents \tRaw Pitch Accuracy:  0.977  ±  0.012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB3Ccb1uEXii",
        "colab_type": "text"
      },
      "source": [
        "## Commercial\n",
        "\n",
        "The commercial recordings used in <a href = \" https://repositori.upf.edu/handle/10230/34975 \">Comparision of the singing style of two jingju schools</a>, are identified with a MusicBrainz ID. With the recording information available on MusicBrainz, the audio files can be found in the <a href = \" https://zenodo.org/record/1475846 \">Jingju Audio Recordings Collection</a>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQFnrqPgkgJ",
        "colab_type": "text"
      },
      "source": [
        "### MELODIA\n",
        "\n",
        "The <a href = \"https://essentia.upf.edu/reference/std_PredominantPitchMelodia.html \">MELODIA</a> algorithm estimates the fundamental frequency of the predominant melody from polyphonic music signals.\n",
        "\n",
        "The following cell runs MELODIA in the commercial recordings for four frame sizes `[512, 1024, 2048, 4096]` and five hop sisez `[128, 256, 441, 512, 1024]`. Then it stores the prediction with the best `Raw Pitch Accuracy` performance for each audio in the `commercial/melodia/` folder.\n",
        "\n",
        "Here, the best `Raw Pitch Accuracy` performance for each audio is determined with the `melody.evaluate` method of the `mir_eval` library. A tolerance of 50 cents is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3mneT2bJG3T",
        "colab_type": "code",
        "outputId": "386eb3bd-7925-4ec6-d4fb-2a9024103d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# executing and storing melodia - commercial\n",
        "test_txt = main_dir + \"commercial/f0_ground_truth/\"\n",
        "test_audio = main_dir + \"commercial/audio/\"\n",
        "melodia_csv = main_dir + \"commercial/melodia/\"\n",
        "os.mkdir(melodia_csv)\n",
        "\n",
        "frameSizes = [512, 1024, 2048, 4096]\n",
        "hopSizes = [128, 256, 441, 512, 1024]\n",
        "fs = 44100\n",
        "count_predictions = 0\n",
        "\n",
        "for root, dirs, files in os.walk(test_txt):\n",
        "    for file in files:\n",
        "        file_name = os.path.join(root,file)\n",
        "        # reading ground-truth\n",
        "        gt_time, gt_pitch = mir_eval.io.load_time_series(file_name)\n",
        "\n",
        "        best_score = 0\n",
        "        x = MonoLoader(filename = test_audio + file.split(\".\")[-2] + \".flac\", downmix = 'mix', sampleRate = fs)() # load labeled audio\n",
        "        x = EqualLoudness()(x)\n",
        "        for frameSize in frameSizes:\n",
        "            for hopSize in hopSizes:\n",
        "                # executing melodia\n",
        "                melodia = PitchMelodia(guessUnvoiced = True, frameSize = frameSize, hopSize = hopSize, sampleRate=fs)\n",
        "                melodia_pitch , melodia_confidence = melodia(x)\n",
        "                melodia_time = np.arange(0,len(melodia_pitch))*hopSize/fs\n",
        "\n",
        "                # melodia_pitch[np.argwhere(melodia_confidence < 0.75)] = 0 # discard prediction with confidence < 0.75\n",
        "                scores = mir_eval.melody.evaluate(gt_time, gt_pitch, melodia_time, melodia_pitch, cent_tolerance=50)\n",
        "                if scores['Raw Pitch Accuracy'] > best_score:\n",
        "                    second_s = best_score\n",
        "                    best_score = scores['Raw Pitch Accuracy']\n",
        "                    best_frameSize = frameSize\n",
        "                    best_hopSize = hopSize     \n",
        "                    best_melodia_time = melodia_time\n",
        "                    best_melodia_pitch = melodia_pitch\n",
        "                    best_melodia_confidence = melodia_confidence\n",
        "        \n",
        "        # storing melodia prediction\n",
        "        with open(melodia_csv + file.split(\".\")[-2] + '.' + str(best_frameSize) + '.' + str(best_hopSize) + \".csv\", 'w') as csv_file:\n",
        "            count_predictions +=1\n",
        "            csv_writer = csv.writer(csv_file, delimiter=',')\n",
        "            for i in range(len(best_melodia_pitch)):\n",
        "                csv_writer.writerow([best_melodia_time[i], best_melodia_pitch[i], best_melodia_confidence[i]])\n",
        "\n",
        "print('{} melodia predictions stored'.format(count_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 melodia predictions stored\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7QQ0tEMi58M",
        "colab_type": "text"
      },
      "source": [
        "Next cell computes the melodia performance on the commercial recordings using the predictions stored in the previous cell. The metric used is the `Raw Pitch Accuracy` which is computed using the `mir_eval.melody.evaluate` method with tolerances of 10, 25 and 50 cents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MzJi0KFksbW",
        "colab_type": "code",
        "outputId": "c0421517-eb67-4438-8adc-b760443dc31b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# evaluating melodia - commercial\n",
        "test_txt = main_dir + \"commercial/f0_ground_truth/\"\n",
        "melodia_csv = main_dir + \"commercial/melodia/\"\n",
        "\n",
        "cent_tolerances = [10, 25, 50]\n",
        "melodia_RPA = {10:[[],[]], 25:[[],[]], 50:[[],[]]} # raw pitch accuracy\n",
        "\n",
        "for root, dirs, files in os.walk(melodia_csv):\n",
        "    for file in files:\n",
        "        file_name = os.path.join(root,file)\n",
        "        # reading melodia prediction\n",
        "        melodia_time = []\n",
        "        melodia_pitch = []\n",
        "        melodia_confidence = []\n",
        "        with open(file_name, mode='r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            for row in csv_reader:\n",
        "                melodia_time.append(float(row[0]))\n",
        "                melodia_pitch.append(float(row[1]))\n",
        "                melodia_confidence.append(float(row[2]))\n",
        "\n",
        "        melodia_time = np.array(melodia_time)\n",
        "        melodia_pitch = np.array(melodia_pitch)\n",
        "        melodia_confidence = np.array(melodia_confidence)\n",
        "\n",
        "        # reading ground-truth\n",
        "        gt_time, gt_pitch = mir_eval.io.load_time_series(test_txt + file.split('.')[-4] + '.txt')\n",
        "  \n",
        "        # melodia_pitch[np.argwhere(melodia_confidence < 0.75)] = 0 # discard prediction with confidence < 0.75    \n",
        "        for cent_tolerance in cent_tolerances:\n",
        "            scores = mir_eval.melody.evaluate(gt_time, gt_pitch, melodia_time, melodia_pitch, cent_tolerance=cent_tolerance)\n",
        "            melodia_RPA[cent_tolerance][0].append( scores['Raw Pitch Accuracy'] )\n",
        "            melodia_RPA[cent_tolerance][1].append( len(gt_time) )\n",
        "\n",
        "print('melodia - commercial')\n",
        "for cent_tolerance in cent_tolerances:\n",
        "    RPA_mean = np.average( melodia_RPA[cent_tolerance][0], weights = melodia_RPA[cent_tolerance][1] )\n",
        "    RPA_std = np.sqrt( np.average((melodia_RPA[cent_tolerance][0] - RPA_mean)**2, weights = melodia_RPA[cent_tolerance][1]) )\n",
        "    print(str(cent_tolerance) + ' cents \\tRaw Pitch Accuracy: ', \"{0:.3f}\".format(RPA_mean), ' ± ', \"{0:.3f}\".format(RPA_std))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "melodia - commercial\n",
            "10 cents \tRaw Pitch Accuracy:  0.695  ±  0.084\n",
            "25 cents \tRaw Pitch Accuracy:  0.775  ±  0.107\n",
            "50 cents \tRaw Pitch Accuracy:  0.794  ±  0.115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt4epzrAPGmH",
        "colab_type": "text"
      },
      "source": [
        "### CREPE\n",
        "\n",
        "Although CREPE is not specifically designed to estimate the predominant melody from polyphonic music signals, here it is used for that purpose in the commercial recordings to provide a performance against which the MELODIA performance could be compared. With a different dataset (<a href = \" http://mac.citi.sinica.edu.tw/ikala/\" >iKala</a>), the same approach is followed in <a href = \" https://arxiv.org/abs/1807.03046 \">Deep Learning for Singing Processing: Achievements, Challenges and Impact on Singers and Listeners</a>.\n",
        "\n",
        "The following cell runs CREPE in the commercial recordings for four time steps `[20, 25, 30, 35]`, and then stores the prediction with the best `Raw Pitch Accuracy` performance for each audio in the `commercial/crepe/` folder.\n",
        "\n",
        "Here, the best `Raw Pitch Accuracy` performance for each audio is determined with the `melody.evaluate` method of the `mir_eval` library. A tolerance of 50 cents is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bj79mRJzramj",
        "colab_type": "code",
        "outputId": "236e2e53-23ee-4763-b23e-49d0333c4f3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# executing and storing crepe - commercial\n",
        "test_txt = main_dir + \"commercial/f0_ground_truth/\"\n",
        "test_audio = main_dir + \"commercial/audio/\"\n",
        "crepe_csv = main_dir + \"commercial/crepe/\"\n",
        "os.mkdir(crepe_csv)\n",
        "\n",
        "fs = 44100\n",
        "steps = [5, 10, 15, 20, 25, 30, 35, 40]\n",
        "count_predictions = 0\n",
        "\n",
        "for root, dirs, files in os.walk(test_txt):\n",
        "    for file in files:\n",
        "        file_name = os.path.join(root,file)\n",
        "        # reading ground-truth\n",
        "        gt_time, gt_pitch = mir_eval.io.load_time_series(file_name)\n",
        "\n",
        "        best_score = 0\n",
        "        audio = MonoLoader(filename = test_audio + file.split(\".\")[-2] + \".flac\", downmix = 'mix', sampleRate = fs)() # load labeled audio \n",
        "        for step in steps:\n",
        "            # executing crepe\n",
        "            crp_time, crp_frequency, crp_confidence, activation = crepe.predict(audio, fs, step_size= step, viterbi=True, verbose=0)\n",
        "\n",
        "            #crp_freq[np.argwhere(crp_confidence < 0.75)] = 0 # discard prediction with confidence < 0.75\n",
        "            scores = mir_eval.melody.evaluate(gt_time, gt_pitch, crp_time, crp_frequency, cent_tolerance=50)\n",
        "            if scores['Raw Pitch Accuracy'] > best_score:\n",
        "                best_score = scores['Raw Pitch Accuracy']\n",
        "                best_step = step\n",
        "                best_crp_time = crp_time\n",
        "                best_crp_frequency = crp_frequency\n",
        "                best_crp_confidence = crp_confidence\n",
        "\n",
        "        # storing crepe output\n",
        "        with open(crepe_csv + file.split(\".\")[-2] + '.' + str(best_step) + \".csv\", mode='w') as csv_file:\n",
        "            count_predictions +=1\n",
        "            csv_writer = csv.writer(csv_file, delimiter=',')\n",
        "            for i in range(len(best_crp_time)):\n",
        "                csv_writer.writerow([best_crp_time[i], best_crp_frequency[i], best_crp_confidence[i]])\n",
        "\n",
        "print('{} crepe predictions stored'.format(count_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 crepe predictions stored\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoWkoxjajEif",
        "colab_type": "text"
      },
      "source": [
        "Next cell computes the CREPE performance on the commercial recordings using the predictions stored in the previous cell. The metric used is the `Raw Pitch Accuracy` which is computed using the `mir_eval.melody.evaluate` method with tolerances of 10, 25 and 50 cents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hueLvg7vranQ",
        "colab_type": "code",
        "outputId": "03f38f52-da2c-4f64-b0ce-f251207383a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# evaluating crepe - commercial\n",
        "test_txt = main_dir + \"commercial/f0_ground_truth/\"\n",
        "crepe_csv = main_dir + \"commercial/crepe/\"\n",
        "\n",
        "cent_tolerances = [10, 25, 50]\n",
        "crp_RPA = {10:[[],[]], 25:[[],[]], 50:[[],[]]} # raw pitch accuracy\n",
        "\n",
        "for root, dirs, files in os.walk(crepe_csv):\n",
        "    for file in files:\n",
        "        file_name = os.path.join(root,file)\n",
        "        # reading crepe prediction\n",
        "        crp_time = []\n",
        "        crp_freq = []\n",
        "        crp_confidence = []\n",
        "        with open(file_name, mode='r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            for row in csv_reader:\n",
        "                crp_time.append(float(row[0]))\n",
        "                crp_freq.append(float(row[1]))\n",
        "                crp_confidence.append(float(row[2]))\n",
        "\n",
        "        crp_time = np.array(crp_time)\n",
        "        crp_freq = np.array(crp_freq)\n",
        "        crp_confidence = np.array(crp_confidence)\n",
        "\n",
        "        # reading ground-truth\n",
        "        gt_time, gt_pitch = mir_eval.io.load_time_series(test_txt + file.split('.')[-3] + '.txt')\n",
        "\n",
        "        #crp_freq[np.argwhere(crp_confidence < 0.75)] = 0 # discard prediction with confidence < 0.75    \n",
        "        for cent_tolerance in cent_tolerances:\n",
        "            scores = mir_eval.melody.evaluate(gt_time, gt_pitch, crp_time, crp_freq, cent_tolerance=cent_tolerance)\n",
        "            crp_RPA[cent_tolerance][0].append( scores['Raw Pitch Accuracy'] )\n",
        "            crp_RPA[cent_tolerance][1].append( len(gt_time) )\n",
        "\n",
        "print('crepe - commercial')\n",
        "for cent_tolerance in cent_tolerances:\n",
        "    RPA_mean = np.average( crp_RPA[cent_tolerance][0], weights = crp_RPA[cent_tolerance][1] )\n",
        "    RPA_std = np.sqrt( np.average((crp_RPA[cent_tolerance][0] - RPA_mean)**2, weights = crp_RPA[cent_tolerance][1]) )\n",
        "    print(str(cent_tolerance) + ' cents \\tRaw Pitch Accuracy: ', \"{0:.3f}\".format(RPA_mean), ' ± ', \"{0:.3f}\".format(RPA_std))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "crepe - commercial\n",
            "10 cents \tRaw Pitch Accuracy:  0.603  ±  0.084\n",
            "25 cents \tRaw Pitch Accuracy:  0.802  ±  0.075\n",
            "50 cents \tRaw Pitch Accuracy:  0.859  ±  0.066\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}